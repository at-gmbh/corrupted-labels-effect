{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import src.evaluation.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path and file filter\n",
    "report_log_path = '../logs/class_report'\n",
    "filter = 'class_report_19epoch.json'\n",
    "\n",
    "# TODO: define metrics to be extracted as list\n",
    "logs = [['accuracy']\n",
    "        , ['macro avg', 'precision']\n",
    "        , ['macro avg', 'recall']\n",
    "        , ['macro avg', 'f1-score']\n",
    "        , ['weighted avg', 'precision']\n",
    "        , ['weighted avg', 'recall']\n",
    "        , ['weighted avg', 'f1-score']\n",
    "]\n",
    "\n",
    "# init dataframe\n",
    "df_headers = ['run', 'model', 'ratio', 'classes', 'metric', 'value']\n",
    "df = pd.DataFrame(columns=df_headers)\n",
    "\n",
    "# iter through logs and get metrics from classification report json files\n",
    "counter = 0\n",
    "for (dirpath, dirnames, filenames) in os.walk(report_log_path):\n",
    "\n",
    "    if filter in filenames:\n",
    "        counter += 1\n",
    "\n",
    "        # set filter file path\n",
    "        file_path = dirpath+'/'+filter\n",
    "        class_report = json.load(open(file_path))\n",
    "\n",
    "        # get relevant metrics\n",
    "        for log in logs:\n",
    "\n",
    "            # transform metrics for readability\n",
    "            run = dirpath.split('\\\\', 1)[-1].replace('\\\\', '_')\n",
    "            model = re.search('(^[a-z]{5,6})_', run).group(1)\n",
    "            ratio = float(re.search('(\\d{5})r', run).group(1)) / 100\n",
    "            classes = re.search('(\\d{1,2})c', run).group(1)\n",
    "            \n",
    "            # based on log definition get metric and metric value from json\n",
    "            if len(log) == 1:\n",
    "                metric = log[0]\n",
    "                value = class_report[log[0]]\n",
    "            elif len(log) == 2:\n",
    "                metric = log[0] + ' ' + log[1]\n",
    "                value = class_report[log[0]][log[1]]\n",
    "            \n",
    "            # init row\n",
    "            row = [\n",
    "                str(run),\n",
    "                str(model),\n",
    "                float(ratio),\n",
    "                str(classes),\n",
    "                str(metric),\n",
    "                float(value)\n",
    "            ]\n",
    "            \n",
    "            # save row to dataframe\n",
    "            df_len = len(df)\n",
    "            df.loc[df_len] = row\n",
    "\n",
    "print(f'{counter} classification reports found - df.shape {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view found metrics\n",
    "df['metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which training setups have less than X runs - TODO: set X\n",
    "x_runs = 20\n",
    "df_runs = df.groupby(['model', 'ratio', 'classes', 'metric']).count().reset_index()\n",
    "df_runs = df_runs.drop('value', axis=1).query('metric == \"accuracy\"')\n",
    "df_runs.query(f'run < {x_runs}').sort_values(by=['model', 'ratio', 'classes'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update model naming\n",
    "def return_model_name(model:str) -> str:\n",
    "    return 'bCNN' if model == 'basic' else 'ResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification metrics for all four setups >> including outliers <<\n",
    "font_size = 15\n",
    "\n",
    "df_temp_main = df.query(f'metric not in [\"macro avg f1-score\", \"macro avg precision\", \"macro avg recall\"]')\n",
    "\n",
    "df_temp_hue = df_temp_main[['model', 'classes']].apply(\n",
    "    lambda row: f'{return_model_name(row.model)}, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "f, axes = plt.subplots(nrows = 1, ncols = 4, figsize = (20, 5))\n",
    "\n",
    "for ind, metric in enumerate(df_temp_main['metric'].unique()):\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    \n",
    "    df_temp_vis = df_temp_main.query(f'metric == \"{metric}\"')\n",
    "    df_temp_vis = df_temp_vis.rename(columns={'value': metric})\n",
    "    # df_temp_vis = util.filter_outliers(df_temp_vis, metric, False, 0)\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=df_temp_vis,\n",
    "        x='ratio',\n",
    "        y=metric,\n",
    "        hue=df_temp_hue,\n",
    "        palette='colorblind',\n",
    "        linewidth=2,\n",
    "        ax = axes[ind]\n",
    "    ).set(\n",
    "        ylim=(0.5,1)\n",
    "    )\n",
    "    \n",
    "    axes[ind].set_xlabel('corrupted labels ratio (%)', size=font_size)\n",
    "    axes[ind].set_ylabel(metric, size=font_size)\n",
    "    axes[ind].set_title(f'{metric.title()} over\\nCorrupted Labels Ratio (with Outlier)\\n', size=font_size)\n",
    "    \n",
    "    if ind == 0:\n",
    "        axes[0].legend(loc='lower left', fontsize=font_size-1)\n",
    "    else:\n",
    "        axes[ind].get_legend().remove()\n",
    "\n",
    "plt.xticks(fontsize=font_size-2)\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.draw()\n",
    "    \n",
    "f.savefig(f'../assets/classification_metrics_overview_withOutliers.png', dpi=300, facecolor='white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification metrics for all four setups >> excluding outliers <<\n",
    "font_size = 15\n",
    "\n",
    "df_temp_main = df.query(f'metric not in [\"macro avg f1-score\", \"macro avg precision\", \"macro avg recall\"]')\n",
    "\n",
    "df_temp_hue = df_temp_main[['model', 'classes']].apply(\n",
    "    lambda row: f'{return_model_name(row.model)}, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "f, axes = plt.subplots(nrows = 1, ncols = 4, figsize = (20, 5))\n",
    "\n",
    "for ind, metric in enumerate(df_temp_main['metric'].unique()):\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    \n",
    "    df_temp_vis = df_temp_main.query(f'metric == \"{metric}\"')\n",
    "    df_temp_vis = df_temp_vis.rename(columns={'value': metric})\n",
    "    df_temp_vis = util.filter_outliers(df_temp_vis, metric, False, 3)\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=df_temp_vis,\n",
    "        x='ratio',\n",
    "        y=metric,\n",
    "        hue=df_temp_hue,\n",
    "        palette='colorblind',\n",
    "        linewidth=1.5,\n",
    "        ax = axes[ind]\n",
    "    ).set(\n",
    "        ylim=(0.5,1)\n",
    "    )\n",
    "\n",
    "    axes[ind].set_xlabel('corrupted labels ratio (%)', size=font_size)\n",
    "    axes[ind].set_ylabel(metric, size=font_size)\n",
    "    axes[ind].set_title(f'{metric.title()} over\\nCorrupted Labels Ratio (with Outlier)\\n', size=font_size)\n",
    "    \n",
    "    if ind == 0:\n",
    "        axes[0].legend(loc='lower left', fontsize=font_size-1)\n",
    "    else:\n",
    "        axes[ind].get_legend().remove()\n",
    "\n",
    "plt.xticks(fontsize=font_size-2)\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.draw()\n",
    "\n",
    "f.savefig(f'../assets/classification_metrics_overview_withoutOutliers.png', dpi=300, facecolor='white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get base stats for classification metrics over average model x classes x ratio setup\n",
    "group_columns = ['model', 'classes', 'ratio', 'metric']\n",
    "\n",
    "df_stats = df.query('metric not in \\\n",
    "            [\"macro avg f1-score\", \"macro avg precision\", \"macro avg recall\"]')\n",
    "df_stats = df_stats.groupby(by=group_columns, as_index=False) \\\n",
    "            .agg({'value':['mean','std']}) \\\n",
    "            .sort_values(group_columns)\n",
    "            \n",
    "df_stats_pivot = df_stats.pivot(index=df_stats[['model', 'classes', 'ratio']], columns='metric')['value'].reset_index()\n",
    "df_stats_pivot.columns = df_stats_pivot.columns.map(' | '.join).str.strip(' | ')\n",
    "\n",
    "print(df_stats_pivot.shape)\n",
    "df_stats_pivot.head()\n",
    "\n",
    "df_stats_pivot.to_excel('../logs/classification_results/classification_metrics_stats_pivot.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## non-aggregated metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "#### accuracy plot per training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_accuracy_setup = df.query(\"metric == 'accuracy'\")\n",
    "df_accuracy_setup['color'] = df_accuracy_setup['model'] + ' ' + df_accuracy_setup['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification accuracy for all four setups as grid plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "g = sns.FacetGrid(\n",
    "    df_accuracy_setup\n",
    "    , col='model'\n",
    "    , row='classes'\n",
    "    , col_order=['basic', 'resnet']\n",
    "    , height = 5\n",
    "    , hue = 'color'\n",
    "    , palette = 'colorblind'\n",
    "    , ylim = (0, 1)\n",
    "    # , xlim = (0,11)\n",
    "    , sharex = True\n",
    "    , sharey = True\n",
    "    , despine = True\n",
    ")\n",
    "g.map(sns.scatterplot, 'ratio', 'value')\n",
    "g.set_axis_labels('corrupted labels ratio', 'model accuracy')\n",
    "\n",
    "g.savefig('../assets/train_setup_model_accuracy.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "#### accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_accuracy = df.query(\"metric == 'accuracy'\")\n",
    "print(df_accuracy.shape)\n",
    "df_accuracy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification accuracy for all four setups as scatter plot\n",
    "df_hue = df_accuracy[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "            data=df_accuracy,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind',\n",
    "            # s=25,\n",
    "            # marker='X'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model accuracy',\n",
    "            ylim=(0.5,1),\n",
    "            title='Model Accuracy over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/model_accuracy.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification accuracy for all four setups as strip plot\n",
    "df_hue = df_accuracy[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.stripplot(\n",
    "            data=df_accuracy,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind',\n",
    "            jitter=0.3,\n",
    "            # s=25,\n",
    "            # marker='X'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model accuracy',\n",
    "            ylim=(0.5,1),\n",
    "            title='Model Accuracy over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/model_accuracy_strip.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### weighted avg precision plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_precision_w = df.query(\"metric == 'weighted avg precision'\")\n",
    "print(df_precision_w.shape)\n",
    "df_precision_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification weighted avg precision for all four setups\n",
    "df_hue = df_precision_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "            data=df_precision_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model precision (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Model Precision (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/model_precision.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### weighted avg recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_recall_w = df.query(\"metric == 'weighted avg recall'\")\n",
    "print(df_recall_w.shape)\n",
    "df_recall_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification weighted avg recall for all four setups\n",
    "df_hue = df_recall_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "            data=df_recall_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model recall (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Model Recall (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/model_recall.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### weighted avg f1-score plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_f1score_w = df.query(\"metric == 'weighted avg f1-score'\")\n",
    "print(df_f1score_w.shape)\n",
    "df_f1score_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification weighted avg f1-score for all four setups\n",
    "df_hue = df_f1score_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "            data=df_f1score_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model f1-score (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Model f1-score (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/model_f1score.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## aggregated (mean) metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate classification results\n",
    "df_aggr = df.query('metric==[\"accuracy\", \"weighted avg precision\", \"weighted avg recall\", \"weighted avg f1-score\"]')\n",
    "df_aggr = df_aggr.groupby(['model', 'classes', 'ratio', 'metric']).mean().reset_index()\n",
    "\n",
    "df_aggr['delta'] = df_aggr.apply(lambda row:\n",
    "    row['value'] - df_aggr.query(f'model==\"{row.model}\" & classes==\"{row.classes}\" & ratio==0.0 & metric==\"{row.metric}\"').iloc[0]['value'], axis=1\n",
    ")\n",
    "\n",
    "df_aggr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "#### aggr accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_aggr_accuracy = df_aggr.query(\"metric == 'accuracy'\")\n",
    "print(df_aggr_accuracy.shape)\n",
    "df_aggr_accuracy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg accuracy for all four setups as line plot\n",
    "df_hue = df_aggr_accuracy[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_accuracy,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model accuracy',\n",
    "            ylim=(0.5,1),\n",
    "            title='Avg. Model Accuracy over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_accuracy.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg accuracy delta for all four setups as line plot\n",
    "font_size = 18\n",
    "\n",
    "df_temp_hue = df_aggr_accuracy[['model', 'classes']].apply(\n",
    "    lambda row: f'{return_model_name(row.model)}, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_accuracy,\n",
    "            x='ratio',\n",
    "            y='delta',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind',\n",
    "            linewidth=2.5\n",
    "        ).set(\n",
    "            ylim=(-0.2,0.05),\n",
    "        )\n",
    "\n",
    "ax1.set_xlabel('corrupted labels ratio (%)', size=font_size)\n",
    "ax1.set_ylabel('avg. accuracy delta', size=font_size)\n",
    "ax1.set_title('Avg. Model Accuracy Delta over Corrupted Labels Ratio\\n', size=font_size)\n",
    "ax1.legend(loc='upper right', fontsize=font_size-1)\n",
    "\n",
    "plt.xticks(fontsize=font_size-2)\n",
    "\n",
    "f.savefig('../assets/avg_model_accuracy_delta.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### aggr weighted avg precision plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_aggr_precision_w = df_aggr.query(\"metric == 'weighted avg precision'\")\n",
    "print(df_aggr_precision_w.shape)\n",
    "df_aggr_precision_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted precision for all four setups as line plot\n",
    "df_hue = df_aggr_precision_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_precision_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model precision (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Avg. Model Precision (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_precision.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted precision delta for all four setups as line plot\n",
    "df_hue = df_aggr_precision_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_precision_w,\n",
    "            x='ratio',\n",
    "            y='delta',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model precision (weighted) delta',\n",
    "            ylim=(-0.15,0.15),\n",
    "            title='Avg. Model Precision (weighted) Delta over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='upper right', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_precision_delta.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### aggr weighted avg recall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_aggr_recall_w = df_aggr.query(\"metric == 'weighted avg recall'\")\n",
    "print(df_aggr_recall_w.shape)\n",
    "df_aggr_recall_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted recall for all four setups as line plot\n",
    "df_hue = df_aggr_recall_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_recall_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model recall (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Avg. Model Recall (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_recall.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted recall delta for all four setups as line plot\n",
    "df_hue = df_aggr_recall_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_recall_w,\n",
    "            x='ratio',\n",
    "            y='delta',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model recall (weighted) delta',\n",
    "            ylim=(-0.2,0.2),\n",
    "            title='Avg. Model Recall (weighted) Delta over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='upper right', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_recall_delta.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "#### aggr weighted avg f1-score plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter classification results\n",
    "df_aggr_f1score_w = df_aggr.query(\"metric == 'weighted avg f1-score'\")\n",
    "print(df_aggr_f1score_w.shape)\n",
    "df_aggr_f1score_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted f1-score for all four setups as line plot\n",
    "df_hue = df_aggr_f1score_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_f1score_w,\n",
    "            x='ratio',\n",
    "            y='value',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model f1-score (weighted)',\n",
    "            ylim=(0.5,1),\n",
    "            title='Avg. Model f1-score (weighted) over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='lower left', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_f1score.png', dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize classification aggregated avg weighted f1-score delta for all four setups as line plot\n",
    "df_hue = df_aggr_f1score_w[['model', 'classes']].apply(\n",
    "    lambda row: f'{row.model} CNN, {row.classes} classes', axis=1\n",
    ")\n",
    "\n",
    "sns.set(font_scale = 1.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(10, 6))\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "sns.lineplot(\n",
    "            data=df_aggr_f1score_w,\n",
    "            x='ratio',\n",
    "            y='delta',\n",
    "            ax=ax1,\n",
    "            hue=df_hue,\n",
    "            palette='colorblind'\n",
    "        ).set(\n",
    "            xlabel='corrupted labels ratio (%)',\n",
    "            ylabel='model f1-score (weighted) delta',\n",
    "            ylim=(-0.2,0.2),\n",
    "            title='Avg. Model f1-score (weighted) Delta over Corrupted Labels Ratio'\n",
    "        )\n",
    "plt.legend(loc='upper right', title='Model Setup', facecolor='white', framealpha=1)\n",
    "\n",
    "f.savefig('../assets/avg_model_f1score_delta.png', dpi=300, facecolor='white')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('false-labels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c041ee5eca0bebec98353fb08f3f656fe2677ac141976eeebd4959b2f854b27b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
