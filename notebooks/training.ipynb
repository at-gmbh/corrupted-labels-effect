{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import src.false_labels_effect.util as util\n",
    "import src.false_labels_effect.data_loader as dl\n",
    "import src.false_labels_effect.models as mdls\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> TODO: set parameter below <--\n",
    "\n",
    "# Select model task\n",
    "#   'Class': main class (4) classification\n",
    "#   'Subclass': sub class (14) classification\n",
    "#   'Annotations' : polygon vertices prediction\n",
    "model_task = 'Class'\n",
    "\n",
    "# set number of images\n",
    "limit_loaded_images = 100  # use None for \"all\" images\n",
    "\n",
    "# set target size of images\n",
    "resize_to = (244, 244) \n",
    "\n",
    "# set ratio of false labels in training data\n",
    "false_ratio = 0\n",
    "\n",
    "# define data loader parameters\n",
    "val_split = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "# define model processing parameter\n",
    "n_epochs = 1\n",
    "multiprocessing = False\n",
    "n_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training and test img png path\n",
    "train_img_png_path = Path(\"..\\\\data\\\\Images_4c_Poly\\\\Train\")\n",
    "test_img_png_path = Path(\"..\\\\data\\\\Images_4c_Poly\\\\Test\")\n",
    "\n",
    "# set training and test img npy path\n",
    "train_img_npy_path = Path('..\\\\data\\\\Images_4c_Poly\\\\Train_npy')\n",
    "test_img_npy_path = Path('..\\\\data\\\\Images_4c_Poly\\\\Test_npy')\n",
    "\n",
    "# set label path\n",
    "train_label_path = Path(\"..\\\\data\\\\Labels_4c_Poly\\\\Train.npy\")\n",
    "test_label_path = Path(\"..\\\\data\\\\Labels_4c_Poly\\\\Test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "train_labels_dict = util.load_labels(train_label_path)\n",
    "test_labels_dict = util.load_labels(test_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train images, resize and save as npy\n",
    "if not os.path.exists(f'{train_img_npy_path}'):\n",
    "    os.mkdir(train_img_npy_path)\n",
    "\n",
    "    i = 0\n",
    "    for image_path in train_img_png_path.iterdir():\n",
    "        i += 1\n",
    "        if limit_loaded_images is not None and i > limit_loaded_images:\n",
    "            break\n",
    "\n",
    "        # Load without resizing so that polygon fits (for now)\n",
    "        img_id = image_path.name.split(\".\")[0]\n",
    "        img = load_img(image_path)\n",
    "\n",
    "        # Use util resize function resize image and polygon\n",
    "        # TODO: poly resize currently not saved\n",
    "        img_res, poly_res = util.resize(\n",
    "            img, train_labels_dict[img_id], resize_to\n",
    "        )\n",
    "\n",
    "        npy_img = img_to_array(img_res)\n",
    "        np.save(f'{train_img_npy_path}\\\\{img_id}', npy_img)\n",
    "\n",
    "# load test images, resize and save as npy\n",
    "if not os.path.exists(f'{test_img_npy_path}'):\n",
    "    os.mkdir(test_img_npy_path)\n",
    "    i = 0\n",
    "\n",
    "    for image_path in test_img_png_path.iterdir():\n",
    "        i += 1\n",
    "        if limit_loaded_images is not None and i > limit_loaded_images:\n",
    "            break\n",
    "\n",
    "        # Load without resizing so that polygon fits (for now)\n",
    "        img_id = image_path.name.split(\".\")[0]\n",
    "        img = load_img(image_path)\n",
    "\n",
    "        # Use util resize function resize image and polygon\n",
    "        # TODO: poly resize currently not saved\n",
    "        img_res, poly_res = util.resize(\n",
    "            img, test_labels_dict[img_id], resize_to\n",
    "        )\n",
    "\n",
    "        npy_img = img_to_array(img_res)\n",
    "        np.save(f'{test_img_npy_path}\\\\{img_id}', npy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of included train and test images formated for keras data loader\n",
    "partition = {}\n",
    "train_img_ids_included = [str(i.name).split(\".\")[0] for i in train_img_npy_path.iterdir()]\n",
    "test_img_ids_included = [str(i.name).split(\".\")[0] for i in test_img_npy_path.iterdir()]\n",
    "\n",
    "# filter for test and train\n",
    "partition['train'] = [id for id in train_img_ids_included if 'Train' in id]\n",
    "partition['test'] = [id for id in test_img_ids_included if 'Test' in id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter train labels to only include transformed images\n",
    "train_labels_dict_incl = {}\n",
    "for (key, value) in train_labels_dict.items():\n",
    "    if key in partition['train']:\n",
    "        train_labels_dict_incl[key] = value\n",
    "\n",
    "# filter test labels to only include transformed images\n",
    "test_labels_dict_incl = {}\n",
    "for (key, value) in test_labels_dict.items():\n",
    "    if key in partition['test']:\n",
    "        test_labels_dict_incl[key] = value\n",
    "\n",
    "# generate flattened dict of model task corresponding labels\n",
    "train_labels_dict_flat = util.select_label(train_labels_dict_incl, model_task)\n",
    "test_labels_dict_flat = util.select_label(test_labels_dict_incl, model_task)\n",
    "\n",
    "# encode categorical labels for classification tasks\n",
    "if model_task in ['Class', 'Subclass']:\n",
    "    y_train, y_test = util.encode_labels(train_labels_dict_flat, test_labels_dict_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into train and validation\n",
    "partition['train'], y_train, partition['val'], y_val = util.train_val_split(partition['train'], y_train, val_split)\n",
    "print('# train imgs:', len(partition['train']), '- # val imgs:', len(partition['val']), '- # test imgs:', len(partition['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of classes in labels\n",
    "if model_task == 'Class':\n",
    "    n_classes = 4\n",
    "elif model_task == 'Subclass':\n",
    "    n_classes = 14\n",
    "\n",
    "# create false train labels\n",
    "y_train = util.make_false_labels(y_train, false_ratio, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader parameters\n",
    "params = {'dim': (resize_to[0],resize_to[1]),\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': n_classes,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# load data\n",
    "training_loader = dl.DataLoader(partition['train'], y_train, **params)\n",
    "validation_loader = dl.DataLoader(partition['val'], y_val, **params) # TODO: currently validation loader is not responding\n",
    "test_loader = dl.DataLoader(partition['test'], y_test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "basic_cnn = mdls.create_cnn_model(resize_to, n_classes)\n",
    "# resnet_cnn = mdls.create_resnet_model(resize_to, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize logging\n",
    "logdir = \"../logs/scalars/\" + basic_cnn._name + \"/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "# compile model and train\n",
    "basic_cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = basic_cnn.fit(x = training_loader,\n",
    "                        epochs = n_epochs,\n",
    "                        verbose = 2,\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        validation_data = validation_loader, # TODO: currently validation loader is not responding\n",
    "                        use_multiprocessing = multiprocessing,\n",
    "                        workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show test accuracy\n",
    "score = basic_cnn.evaluate(x = test_loader,\n",
    "                           batch_size = batch_size,\n",
    "                           use_multiprocessing = multiprocessing,\n",
    "                           workers = n_workers,\n",
    "                           verbose = 0)\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show logs:\n",
    "# %tensorboard --logdir ../logs/scalars # or http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "785473fea46f9ac689a96b3810ed86c0f03e438ffd4c73e9fe241b9bd8d70125"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('false-labels': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
